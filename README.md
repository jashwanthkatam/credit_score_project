ğŸ’³ Credit Score Classification Project:


ğŸ“Š Overview

Welcome! This project demonstrates how to build an intelligent credit score classification system for a global finance company.

Imagine youâ€™re a data scientist at a large financial institution â€” 
youâ€™ve got access to extensive customer bank details and credit-related data. The goal? 
â¡ï¸ Reduce manual work by automatically classifying customers into credit score brackets, enabling faster decisions and better risk management.


ğŸ—‚ï¸ Dataset

ğŸ“Œ Source: Kaggle Credit Score Dataset

Records: 100,000 entries across 28 features.

Features Include:

Unique IDs for customers and transactions

Credit scores

Bank details

Demographic information

![image](https://github.com/user-attachments/assets/d24ad6c9-3a61-4d93-98f5-557ec1d6c438)


âš™ï¸ Steps & Methodology


1ï¸âƒ£ Import Libraries
Essential libraries like pandas, numpy, matplotlib, and seaborn were imported to handle data and visualization tasks.


2ï¸âƒ£ Data Cleaning ğŸ§¹
Removed special characters and replaced them with NaN values where appropriate.

Converted string fields to numeric types (int or float).

Filled missing values using forward-fill and backward-fill methods.

Removed outliers (e.g., for age) to maintain data integrity.

Applied One Hot Encoding to categorical variables.

![image](https://github.com/user-attachments/assets/301398bd-c8f9-42b2-995d-95363b886da5)


3ï¸âƒ£ Feature Selection ğŸ”
âœ… Used Variance Inflation Factor (VIF) to check for multicollinearity â€” ensuring VIF < 5 for selected features.
âœ… Retained all relevant features based on these checks.

![image](https://github.com/user-attachments/assets/15faf05d-0d20-4310-8d9e-87ac8992b73d)


4ï¸âƒ£ Model Building & Evaluation ğŸ¤–

Model	Accuracy
Logistic Regression	61.8%
Decision Tree	69.7%
Decision Tree (Hyperparameter Tuned)	70.9%
Random Forest	79.7%

![image](https://github.com/user-attachments/assets/ec7134bb-3298-4e87-83c5-2ca51e33e055)


Techniques Used:

Logistic Regression: Baseline model for binary classification.

Decision Tree: Improved interpretability with decent performance.

GridSearchCV: Hyperparameter tuning for optimal Decision Tree performance.

Random Forest: Achieved the highest accuracy, leveraging ensemble learning.



ğŸ“ˆ Key Learnings


âœ… Data cleaning and proper handling of missing values greatly improved model performance.
âœ… Feature selection using VIF helped avoid multicollinearity.
âœ… Ensemble methods like Random Forest provided significant accuracy improvements compared to single classifiers.

ğŸš€ Future Improvements
âœ¨ Test other advanced ensemble techniques like XGBoost or LightGBM.
âœ¨ Deploy the model as an API for real-time credit score classification.
âœ¨ Implement feature importance analysis to explain predictions to stakeholders.

ğŸ™Œ Credits
Dataset by link: (https://www.kaggle.com/datasets/parisrohan/credit-score-classification)
Developed by Jashwanth Katam

Feel free to â­ this repo if you found it helpful!
Pull requests and suggestions are always welcome. ğŸ¤
